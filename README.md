ChatWithLlama4
ChatWithLlama4 is a Python application that enables users to interact with Meta's LLaMA 4 model using LangChain and LangGraph frameworks. This project showcases how to build conversational AI systems by integrating large language models with graph-based state management.

Features
Conversational AI: Engage in dynamic conversations with the LLaMA 4 model.

Graph-Based State Management: Utilize LangGraph to manage conversation state transitions.

Integration with LangChain: Leverage LangChain's capabilities to enhance AI interactions.

Prerequisites
Python 3.8 or higher

Access to the Groq API with a valid GROQ_API_KEY

Installation
Clone the Repository:

git clone https://github.com/GnanaSelvan2025/chatwithllama4.git
cd chatwithllama4

Install Required Packages:
pip install -r requirements.txt

Configuration
Set the following environment variables:

GROQ_API_KEY: Your Groq API key.

LANGCHAIN_TRACING_V2: Set to 'true' to enable LangChain tracing.

LANGCHAIN_API_KEY: Your LangChain API key.

LANGCHAIN_PROJECT: Set to 'LiveLanggraph' or your preferred project name.
